# =============================================================================
# BigRAG Cinema -- Spark Defaults
# =============================================================================
# This file mirrors the format of $SPARK_HOME/conf/spark-defaults.conf.
# Each line is a key-value pair separated by whitespace.
# Uncomment and adjust values as needed for your environment.
#
# These defaults are overridden by anything set programmatically in
# SparkSession.builder.config() or via cluster_profiles/*.yaml.
# =============================================================================

# ---- Application metadata ---------------------------------------------------
# spark.app.name                     BigRAG-Cinema
# spark.app.id                       (auto-generated)

# ---- Master / deploy mode ---------------------------------------------------
# For local development, use local[*] to utilize all cores.
# spark.master                       local[*]

# ---- Driver settings ---------------------------------------------------------
# spark.driver.memory                4g
# spark.driver.cores                 2
# spark.driver.maxResultSize         2g

# ---- Executor settings -------------------------------------------------------
# spark.executor.memory              4g
# spark.executor.cores               2
# spark.executor.instances           1

# ---- Serialization -----------------------------------------------------------
# Kryo is faster than Java serialization for most workloads.
# spark.serializer                   org.apache.spark.serializer.KryoSerializer
# spark.kryoserializer.buffer.max    512m

# ---- Shuffle & parallelism ---------------------------------------------------
# spark.sql.shuffle.partitions       200
# spark.default.parallelism          8

# ---- I/O & Parquet -----------------------------------------------------------
# spark.sql.parquet.compression.codec   snappy
# spark.sql.parquet.mergeSchema         false

# ---- Arrow / Pandas interop --------------------------------------------------
# Required for efficient toPandas() / createDataFrame(pdf).
# spark.sql.execution.arrow.pyspark.enabled   true

# ---- UI / logging ------------------------------------------------------------
# spark.ui.enabled                   true
# spark.ui.port                      4040
# spark.eventLog.enabled             false
# spark.eventLog.dir                 /tmp/spark-events

# ---- Miscellaneous -----------------------------------------------------------
# spark.sql.adaptive.enabled         true
# spark.sql.adaptive.coalescePartitions.enabled   true
