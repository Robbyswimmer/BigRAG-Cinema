# =============================================================================
# BigRAG Cinema -- Python Logging Configuration (dictConfig format)
# =============================================================================
# Load with:
#     import yaml, logging.config
#     with open("conf/logging.yaml") as f:
#         logging.config.dictConfig(yaml.safe_load(f))
# =============================================================================

version: 1
disable_existing_loggers: false

# ---- Formatters --------------------------------------------------------------
formatters:
  standard:
    format: "%(asctime)s [%(levelname)-8s] %(name)s: %(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"

  verbose:
    format: "%(asctime)s [%(levelname)-8s] %(name)s (%(filename)s:%(lineno)d) -- %(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"

  brief:
    format: "[%(levelname)s] %(message)s"

# ---- Handlers ----------------------------------------------------------------
handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: standard
    stream: ext://sys.stdout

  file_debug:
    class: logging.handlers.RotatingFileHandler
    level: DEBUG
    formatter: verbose
    filename: logs/bigrag_debug.log
    maxBytes: 10485760          # 10 MB
    backupCount: 3
    encoding: utf-8

  file_error:
    class: logging.FileHandler
    level: ERROR
    formatter: verbose
    filename: logs/bigrag_errors.log
    encoding: utf-8

# ---- Loggers -----------------------------------------------------------------
loggers:
  # Root application logger
  bigrag_cinema:
    level: DEBUG
    handlers: [console, file_debug]
    propagate: false

  # Benchmark harness
  bigrag_cinema.benchmark:
    level: DEBUG
    handlers: [console, file_debug]
    propagate: false

  # Embedding pipeline
  bigrag_cinema.embedding:
    level: INFO
    handlers: [console, file_debug]
    propagate: false

  # Spark-related logging (reduce noise from Spark internals)
  py4j:
    level: WARN
    handlers: [console]
    propagate: false

  pyspark:
    level: WARN
    handlers: [console]
    propagate: false

# ---- Root logger (catch-all) -------------------------------------------------
root:
  level: WARNING
  handlers: [console, file_error]
